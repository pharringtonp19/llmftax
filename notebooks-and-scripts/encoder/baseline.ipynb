{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax \n",
    "import jax.numpy as jnp \n",
    "from transformers import AutoTokenizer, FlaxAutoModelForSequenceClassification\n",
    "from datasets import load_dataset\n",
    "import optax "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Plotting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Font location: ./../../styles/Newsreader\n",
      "First font file: /home/ubuntu/llmftax/styles/Newsreader/static/Newsreader_14pt/Newsreader_14pt-ExtraLight.ttf\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "from matplotlib import font_manager\n",
    "\n",
    "# Configure matplotlib parameters\n",
    "rcParams['image.interpolation'] = 'nearest'\n",
    "rcParams['image.cmap'] = 'viridis'\n",
    "rcParams['axes.grid'] = False\n",
    "\n",
    "# Enable inline plotting for Jupyter notebooks and use SVG format for higher quality\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "# Set the style for plots\n",
    "plt.style.use('seaborn-v0_8-dark-palette')\n",
    "\n",
    "# Define the location of the custom font files\n",
    "font_location = './../../styles/Newsreader'\n",
    "\n",
    "# Find all font files in the specified location\n",
    "font_files = font_manager.findSystemFonts(fontpaths=font_location)\n",
    "\n",
    "# Print the font location and the first font file found for verification\n",
    "print(f\"Font location: {font_location}\")\n",
    "print(f\"First font file: {font_files[0]}\")\n",
    "\n",
    "# Add all the found font files to the font manager\n",
    "for font_file in font_files:\n",
    "    font_manager.fontManager.addfont(font_file)\n",
    "\n",
    "# Set the default font family to the custom font\n",
    "plt.rcParams[\"font.family\"] = \"Newsreader\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = 'roberta-base'\n",
    "epochs = 10\n",
    "batch_size = 32 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Tokenizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/llmftax/llms/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.model_max_length = 512\n",
    "\n",
    "def tokenizer_function(example):\n",
    "    return tokenizer(example['text'], truncation=True, padding='max_length')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-16 16:21:15.725030: W external/xla/xla/service/gpu/nvptx_compiler.cc:760] The NVIDIA driver's CUDA version is 12.2 which is older than the ptxas CUDA version (12.4.131). Because the driver is older than the ptxas version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing FlaxRobertaForSequenceClassification: {('lm_head', 'dense', 'kernel'), ('lm_head', 'dense', 'bias'), ('lm_head', 'layer_norm', 'bias'), ('lm_head', 'bias'), ('lm_head', 'layer_norm', 'scale')}\n",
      "- This IS expected if you are initializing FlaxRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing FlaxRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of FlaxRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: {('classifier', 'out_proj', 'kernel'), ('classifier', 'dense', 'kernel'), ('classifier', 'out_proj', 'bias'), ('classifier', 'dense', 'bias')}\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = FlaxAutoModelForSequenceClassification.from_pretrained(model_id,\n",
    "                                                           num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dataset = load_dataset(\"ppower1/instrument\")['train']\n",
    "device = str(jax.devices()[0])\n",
    "original_dataset = original_dataset.with_format(\"jax\", device=device)\n",
    "\n",
    "def check_prefix(example):\n",
    "    example['type_indicator'] = 1 if example['text'].startswith('Yes') else 0\n",
    "    return example\n",
    "original_dataset = original_dataset.map(check_prefix)\n",
    "dataset = original_dataset.train_test_split(test_size=0.5, seed=42)\n",
    "tokenized_dataset = dataset.map(tokenizer_function, batched=True)\n",
    "tokenized_dataset = tokenized_dataset.remove_columns(['text', 'treated text', 'control text', 'raw_label'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(params, batch):\n",
    "    # Perform a forward pass through the model to get the logits\n",
    "    logits = model(params=params, input_ids=batch['input_ids'], attention_mask=batch['attention_mask']).logits\n",
    "    \n",
    "    # Get the true labels from the batch\n",
    "    labels = batch['label']\n",
    "    \n",
    "    # Compute the two-class cross-entropy loss\n",
    "    loss = optax.softmax_cross_entropy_with_integer_labels(logits, labels)\n",
    "    \n",
    "    # Return the average loss across the batch\n",
    "    return jnp.mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.80822366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-16 16:21:46.581820: W external/tsl/tsl/framework/bfc_allocator.cc:482] Allocator (GPU_0_bfc) ran out of memory trying to allocate 192.00MiB (rounded to 201326592)requested by op \n",
      "2024-05-16 16:21:46.582628: W external/tsl/tsl/framework/bfc_allocator.cc:494] ****************************************************************************************************\n",
      "E0516 16:21:46.582682    9021 pjrt_stream_executor_client.cc:2826] Execution of replica 0 failed: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 201326592 bytes.\n",
      "BufferAssignment OOM Debugging.\n",
      "BufferAssignment stats:\n",
      "             parameter allocation:  192.00MiB\n",
      "              constant allocation:         0B\n",
      "        maybe_live_out allocation:  192.00MiB\n",
      "     preallocated temp allocation:         0B\n",
      "                 total allocation:  384.00MiB\n",
      "              total fragmentation:         0B (0.00%)\n",
      "Peak buffers:\n",
      "\tBuffer 1:\n",
      "\t\tSize: 192.00MiB\n",
      "\t\tEntry Parameter Subshape: f32[32,512,3072]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 2:\n",
      "\t\tSize: 192.00MiB\n",
      "\t\tXLA Label: fusion\n",
      "\t\tShape: f32[32,512,3072]\n",
      "\t\t==========================\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "RESOURCE_EXHAUSTED: Out of memory while trying to allocate 201326592 bytes.\nBufferAssignment OOM Debugging.\nBufferAssignment stats:\n             parameter allocation:  192.00MiB\n              constant allocation:         0B\n        maybe_live_out allocation:  192.00MiB\n     preallocated temp allocation:         0B\n                 total allocation:  384.00MiB\n              total fragmentation:         0B (0.00%)\nPeak buffers:\n\tBuffer 1:\n\t\tSize: 192.00MiB\n\t\tEntry Parameter Subshape: f32[32,512,3072]\n\t\t==========================\n\n\tBuffer 2:\n\t\tSize: 192.00MiB\n\t\tXLA Label: fusion\n\t\tShape: f32[32,512,3072]\n\t\t==========================\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[1;32m      5\u001b[0m     \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m tokenized_dataset[\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39miter(batch_size\u001b[39m=\u001b[39mbatch_size):\n\u001b[0;32m----> 6\u001b[0m         loss, grads \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39;49mvalue_and_grad(loss_fn)(params, batch)\n\u001b[1;32m      7\u001b[0m         updates, opt_state \u001b[39m=\u001b[39m opt\u001b[39m.\u001b[39mupdate(grads, opt_state, params)\n\u001b[1;32m      8\u001b[0m         params \u001b[39m=\u001b[39m optax\u001b[39m.\u001b[39mapply_updates(params, updates)\n",
      "    \u001b[0;31m[... skipping hidden 8 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m, in \u001b[0;36mloss_fn\u001b[0;34m(params, batch)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mloss_fn\u001b[39m(params, batch):\n\u001b[1;32m      2\u001b[0m     \u001b[39m# Perform a forward pass through the model to get the logits\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     logits \u001b[39m=\u001b[39m model(params\u001b[39m=\u001b[39;49mparams, input_ids\u001b[39m=\u001b[39;49mbatch[\u001b[39m'\u001b[39;49m\u001b[39minput_ids\u001b[39;49m\u001b[39m'\u001b[39;49m], attention_mask\u001b[39m=\u001b[39;49mbatch[\u001b[39m'\u001b[39;49m\u001b[39mattention_mask\u001b[39;49m\u001b[39m'\u001b[39;49m])\u001b[39m.\u001b[39mlogits\n\u001b[1;32m      5\u001b[0m     \u001b[39m# Get the true labels from the batch\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     labels \u001b[39m=\u001b[39m batch[\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m~/llmftax/llms/lib/python3.10/site-packages/transformers/models/roberta/modeling_flax_roberta.py:898\u001b[0m, in \u001b[0;36mFlaxRobertaPreTrainedModel.__call__\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, encoder_hidden_states, encoder_attention_mask, params, dropout_rng, train, output_attentions, output_hidden_states, return_dict, past_key_values)\u001b[0m\n\u001b[1;32m    895\u001b[0m         outputs \u001b[39m=\u001b[39m outputs[:\u001b[39m1\u001b[39m] \u001b[39m+\u001b[39m (unfreeze(past_key_values[\u001b[39m\"\u001b[39m\u001b[39mcache\u001b[39m\u001b[39m\"\u001b[39m]),) \u001b[39m+\u001b[39m outputs[\u001b[39m1\u001b[39m:]\n\u001b[1;32m    897\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 898\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodule\u001b[39m.\u001b[39;49mapply(\n\u001b[1;32m    899\u001b[0m         inputs,\n\u001b[1;32m    900\u001b[0m         jnp\u001b[39m.\u001b[39;49marray(input_ids, dtype\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mi4\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    901\u001b[0m         jnp\u001b[39m.\u001b[39;49marray(attention_mask, dtype\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mi4\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    902\u001b[0m         token_type_ids\u001b[39m=\u001b[39;49mjnp\u001b[39m.\u001b[39;49marray(token_type_ids, dtype\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mi4\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    903\u001b[0m         position_ids\u001b[39m=\u001b[39;49mjnp\u001b[39m.\u001b[39;49marray(position_ids, dtype\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mi4\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    904\u001b[0m         head_mask\u001b[39m=\u001b[39;49mjnp\u001b[39m.\u001b[39;49marray(head_mask, dtype\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mi4\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    905\u001b[0m         deterministic\u001b[39m=\u001b[39;49m\u001b[39mnot\u001b[39;49;00m train,\n\u001b[1;32m    906\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    907\u001b[0m         output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m    908\u001b[0m         return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m    909\u001b[0m         rngs\u001b[39m=\u001b[39;49mrngs,\n\u001b[1;32m    910\u001b[0m     )\n\u001b[1;32m    912\u001b[0m \u001b[39mreturn\u001b[39;00m outputs\n",
      "    \u001b[0;31m[... skipping hidden 6 frame]\u001b[0m\n",
      "File \u001b[0;32m~/llmftax/llms/lib/python3.10/site-packages/transformers/models/roberta/modeling_flax_roberta.py:1097\u001b[0m, in \u001b[0;36mFlaxRobertaForSequenceClassificationModule.__call__\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, deterministic, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1084\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\n\u001b[1;32m   1085\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   1086\u001b[0m     input_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1095\u001b[0m ):\n\u001b[1;32m   1096\u001b[0m     \u001b[39m# Model\u001b[39;00m\n\u001b[0;32m-> 1097\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mroberta(\n\u001b[1;32m   1098\u001b[0m         input_ids,\n\u001b[1;32m   1099\u001b[0m         attention_mask,\n\u001b[1;32m   1100\u001b[0m         token_type_ids,\n\u001b[1;32m   1101\u001b[0m         position_ids,\n\u001b[1;32m   1102\u001b[0m         head_mask,\n\u001b[1;32m   1103\u001b[0m         deterministic\u001b[39m=\u001b[39;49mdeterministic,\n\u001b[1;32m   1104\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1105\u001b[0m         output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1106\u001b[0m         return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1107\u001b[0m     )\n\u001b[1;32m   1109\u001b[0m     sequence_output \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1110\u001b[0m     logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclassifier(sequence_output, deterministic\u001b[39m=\u001b[39mdeterministic)\n",
      "    \u001b[0;31m[... skipping hidden 2 frame]\u001b[0m\n",
      "File \u001b[0;32m~/llmftax/llms/lib/python3.10/site-packages/transformers/models/roberta/modeling_flax_roberta.py:957\u001b[0m, in \u001b[0;36mFlaxRobertaModule.__call__\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, encoder_hidden_states, encoder_attention_mask, init_cache, deterministic, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    952\u001b[0m     position_ids \u001b[39m=\u001b[39m jnp\u001b[39m.\u001b[39mbroadcast_to(jnp\u001b[39m.\u001b[39marange(jnp\u001b[39m.\u001b[39matleast_2d(input_ids)\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]), input_ids\u001b[39m.\u001b[39mshape)\n\u001b[1;32m    954\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(\n\u001b[1;32m    955\u001b[0m     input_ids, token_type_ids, position_ids, attention_mask, deterministic\u001b[39m=\u001b[39mdeterministic\n\u001b[1;32m    956\u001b[0m )\n\u001b[0;32m--> 957\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[1;32m    958\u001b[0m     hidden_states,\n\u001b[1;32m    959\u001b[0m     attention_mask,\n\u001b[1;32m    960\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m    961\u001b[0m     deterministic\u001b[39m=\u001b[39;49mdeterministic,\n\u001b[1;32m    962\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m    963\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_attention_mask,\n\u001b[1;32m    964\u001b[0m     init_cache\u001b[39m=\u001b[39;49minit_cache,\n\u001b[1;32m    965\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    966\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m    967\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m    968\u001b[0m )\n\u001b[1;32m    969\u001b[0m hidden_states \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    970\u001b[0m pooled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(hidden_states) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_pooling_layer \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping hidden 2 frame]\u001b[0m\n",
      "File \u001b[0;32m~/llmftax/llms/lib/python3.10/site-packages/transformers/models/roberta/modeling_flax_roberta.py:624\u001b[0m, in \u001b[0;36mFlaxRobertaEncoder.__call__\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, init_cache, deterministic, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\n\u001b[1;32m    612\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    613\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    622\u001b[0m     return_dict: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    623\u001b[0m ):\n\u001b[0;32m--> 624\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayer(\n\u001b[1;32m    625\u001b[0m         hidden_states,\n\u001b[1;32m    626\u001b[0m         attention_mask,\n\u001b[1;32m    627\u001b[0m         head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m    628\u001b[0m         encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m    629\u001b[0m         encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_attention_mask,\n\u001b[1;32m    630\u001b[0m         init_cache\u001b[39m=\u001b[39;49minit_cache,\n\u001b[1;32m    631\u001b[0m         deterministic\u001b[39m=\u001b[39;49mdeterministic,\n\u001b[1;32m    632\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    633\u001b[0m         output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m    634\u001b[0m         return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m    635\u001b[0m     )\n",
      "    \u001b[0;31m[... skipping hidden 2 frame]\u001b[0m\n",
      "File \u001b[0;32m~/llmftax/llms/lib/python3.10/site-packages/transformers/models/roberta/modeling_flax_roberta.py:563\u001b[0m, in \u001b[0;36mFlaxRobertaLayerCollection.__call__\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, init_cache, deterministic, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    560\u001b[0m \u001b[39mif\u001b[39;00m output_hidden_states:\n\u001b[1;32m    561\u001b[0m     all_hidden_states \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (hidden_states,)\n\u001b[0;32m--> 563\u001b[0m layer_outputs \u001b[39m=\u001b[39m layer(\n\u001b[1;32m    564\u001b[0m     hidden_states,\n\u001b[1;32m    565\u001b[0m     attention_mask,\n\u001b[1;32m    566\u001b[0m     head_mask[i] \u001b[39mif\u001b[39;49;00m head_mask \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    567\u001b[0m     encoder_hidden_states,\n\u001b[1;32m    568\u001b[0m     encoder_attention_mask,\n\u001b[1;32m    569\u001b[0m     init_cache,\n\u001b[1;32m    570\u001b[0m     deterministic,\n\u001b[1;32m    571\u001b[0m     output_attentions,\n\u001b[1;32m    572\u001b[0m )\n\u001b[1;32m    574\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    576\u001b[0m \u001b[39mif\u001b[39;00m output_attentions:\n",
      "    \u001b[0;31m[... skipping hidden 2 frame]\u001b[0m\n",
      "File \u001b[0;32m~/llmftax/llms/lib/python3.10/site-packages/transformers/models/roberta/modeling_flax_roberta.py:503\u001b[0m, in \u001b[0;36mFlaxRobertaLayer.__call__\u001b[0;34m(self, hidden_states, attention_mask, layer_head_mask, encoder_hidden_states, encoder_attention_mask, init_cache, deterministic, output_attentions)\u001b[0m\n\u001b[1;32m    493\u001b[0m     cross_attention_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcrossattention(\n\u001b[1;32m    494\u001b[0m         attention_output,\n\u001b[1;32m    495\u001b[0m         attention_mask\u001b[39m=\u001b[39mencoder_attention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    499\u001b[0m         output_attentions\u001b[39m=\u001b[39moutput_attentions,\n\u001b[1;32m    500\u001b[0m     )\n\u001b[1;32m    501\u001b[0m     attention_output \u001b[39m=\u001b[39m cross_attention_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m--> 503\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mintermediate(attention_output)\n\u001b[1;32m    504\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput(hidden_states, attention_output, deterministic\u001b[39m=\u001b[39mdeterministic)\n\u001b[1;32m    506\u001b[0m outputs \u001b[39m=\u001b[39m (hidden_states,)\n",
      "    \u001b[0;31m[... skipping hidden 2 frame]\u001b[0m\n",
      "File \u001b[0;32m~/llmftax/llms/lib/python3.10/site-packages/transformers/models/roberta/modeling_flax_roberta.py:432\u001b[0m, in \u001b[0;36mFlaxRobertaIntermediate.__call__\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, hidden_states):\n\u001b[1;32m    431\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdense(hidden_states)\n\u001b[0;32m--> 432\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mactivation(hidden_states)\n\u001b[1;32m    433\u001b[0m     \u001b[39mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m~/llmftax/llms/lib/python3.10/site-packages/jax/_src/nn/functions.py:454\u001b[0m, in \u001b[0;36mgelu\u001b[0;34m(x, approximate)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    453\u001b[0m   sqrt_2 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msqrt(\u001b[39m2\u001b[39m)\u001b[39m.\u001b[39mastype(x_arr\u001b[39m.\u001b[39mdtype)\n\u001b[0;32m--> 454\u001b[0m   \u001b[39mreturn\u001b[39;00m jnp\u001b[39m.\u001b[39;49marray(x_arr \u001b[39m*\u001b[39;49m (lax\u001b[39m.\u001b[39;49merf(x_arr \u001b[39m/\u001b[39;49m sqrt_2) \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m) \u001b[39m/\u001b[39;49m \u001b[39m2\u001b[39;49m, dtype\u001b[39m=\u001b[39;49mx_arr\u001b[39m.\u001b[39;49mdtype)\n",
      "File \u001b[0;32m~/llmftax/llms/lib/python3.10/site-packages/jax/_src/numpy/lax_numpy.py:2608\u001b[0m, in \u001b[0;36marray\u001b[0;34m(object, dtype, copy, order, ndmin)\u001b[0m\n\u001b[1;32m   2605\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2606\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnexpected input type for array: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(\u001b[39mobject\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 2608\u001b[0m out_array: Array \u001b[39m=\u001b[39m lax_internal\u001b[39m.\u001b[39;49m_convert_element_type(\n\u001b[1;32m   2609\u001b[0m     out, dtype, weak_type\u001b[39m=\u001b[39;49mweak_type)\n\u001b[1;32m   2610\u001b[0m \u001b[39mif\u001b[39;00m ndmin \u001b[39m>\u001b[39m ndim(out_array):\n\u001b[1;32m   2611\u001b[0m   out_array \u001b[39m=\u001b[39m lax\u001b[39m.\u001b[39mexpand_dims(out_array, \u001b[39mrange\u001b[39m(ndmin \u001b[39m-\u001b[39m ndim(out_array)))\n",
      "    \u001b[0;31m[... skipping hidden 8 frame]\u001b[0m\n",
      "File \u001b[0;32m~/llmftax/llms/lib/python3.10/site-packages/jax/_src/dispatch.py:86\u001b[0m, in \u001b[0;36mapply_primitive\u001b[0;34m(prim, *args, **params)\u001b[0m\n\u001b[1;32m     84\u001b[0m prev \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39mjax_jit\u001b[39m.\u001b[39mswap_thread_local_state_disable_jit(\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m     85\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 86\u001b[0m   outs \u001b[39m=\u001b[39m fun(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m     87\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     88\u001b[0m   lib\u001b[39m.\u001b[39mjax_jit\u001b[39m.\u001b[39mswap_thread_local_state_disable_jit(prev)\n",
      "\u001b[0;31mValueError\u001b[0m: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 201326592 bytes.\nBufferAssignment OOM Debugging.\nBufferAssignment stats:\n             parameter allocation:  192.00MiB\n              constant allocation:         0B\n        maybe_live_out allocation:  192.00MiB\n     preallocated temp allocation:         0B\n                 total allocation:  384.00MiB\n              total fragmentation:         0B (0.00%)\nPeak buffers:\n\tBuffer 1:\n\t\tSize: 192.00MiB\n\t\tEntry Parameter Subshape: f32[32,512,3072]\n\t\t==========================\n\n\tBuffer 2:\n\t\tSize: 192.00MiB\n\t\tXLA Label: fusion\n\t\tShape: f32[32,512,3072]\n\t\t==========================\n\n"
     ]
    }
   ],
   "source": [
    "opt = optax.sgd(learning_rate=1e-4)\n",
    "params = model.params\n",
    "opt_state = opt.init(params)\n",
    "for epoch in range(epochs):\n",
    "    for batch in tokenized_dataset['train'].iter(batch_size=batch_size):\n",
    "        loss, grads = jax.value_and_grad(loss_fn)(params, batch)\n",
    "        updates, opt_state = opt.update(grads, opt_state, params)\n",
    "        params = optax.apply_updates(params, updates)\n",
    "        print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
